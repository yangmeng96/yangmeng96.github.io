---
title: "Weakly-Supervised Multimodal Learning on MIMIC-CXR"
collection: publications
permalink: /publication/2024-03-01-mimic
excerpt: 'This paper is about MM-VAMP VAE, a multimodal variational autoencoder that allows latent representation sharing, obtained by a mixture-of-experts prior with a soft constraint, inspired by the Jensen-Shannon Divergence in contrastive learning, that is great at downstream tasks in representation learning and missing modality imputation, in both simulation study and a real world neuron activity datasets.'
date: 2024-03-08
venue: 'Advances in Neural Information Processing Systems 38 (NeurIPS 2024)'
paperurl: 'https://arxiv.org/pdf/2403.05300.pdf'
citation: 'Sutter T. M., Meng Y., Agostini A., Chopard D., Fortin N., Vogt J. E., Shahbaba B., Mandt S. (2024). &quot;Unity by Diversity: Improved Representation Learning in Multimodal VAEs&quot; <i>arXiv Preprint</i> arXiv: 2403.05300, 2024.'
---

Multimodal data integration and label scarcity pose significant challenges for machine learning in medical settings. To address these issues, we conduct an in-depth evaluation of the newly proposed Multimodal Variational Mixture-ofExperts (MMVM) VAE on the challenging MIMIC-CXR dataset. Our analysis demonstrates that the MMVM VAE consistently outperforms other multimodal VAEs and fully supervised approaches, highlighting its strong potential for real-world medical applications.

Keywords: Multimodal Learning; Representation Learning, Multimodal Learning, Medical Imaging Analysis, Chest X-rays
